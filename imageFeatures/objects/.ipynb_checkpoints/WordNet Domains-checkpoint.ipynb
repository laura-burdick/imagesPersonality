{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given raw image features, calculate wordnet domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change these variables to work with your data\n",
    "home = '/local/image_personality/image_data/data2016/'\n",
    "IMAGE_FEATURES_FILE = home+\"image_features/features_image_all_averages.csv\" #all average object detections\n",
    "SENSEMAP_FILE_MONO = \"/local/software/wn-domains-3.2/sensemap-2.1-3.0/2.1to3.0.noun.mono\" #Mapping WordNet domains from WordNet 2.1 to WordNet 3.0 for monosemous nouns\n",
    "SENSEMAP_FILE_POLY = \"/local/software/wn-domains-3.2/sensemap-2.1-3.0/2.1to3.0.noun.poly\" #Mapping WordNet domains from WordNet 2.1 to WordNet 3.0 for polysemous nouns\n",
    "WORDNET_DOMAINS = \"/local/software/wn-domains-3.2/wn-domains-3.2-20070223\"\n",
    "OUTPUT_FILE = home+\"image_features/features_objects_wordnet_domains.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imageFeatures = pd.read_csv(IMAGE_FEATURES_FILE)\n",
    "imageFeatures = imageFeatures.drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objs = [i for i in imageFeatures.columns.values if i[:8]==\"IMAGENET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load WordNet 2.1 to 3.0 mappings\n",
    "mono_mapping0 = pd.read_csv(SENSEMAP_FILE_MONO,header=None,sep=' ')\n",
    "\n",
    "mono_mapping0['2.1_sense_key'] = [i[:-2] for i in mono_mapping0[0]]\n",
    "mono_mapping0['2.1_synset_offset'] = mono_mapping0[1]\n",
    "mono_mapping0['3.0_sense_key'] = [i[:-2] for i in mono_mapping0[2]]\n",
    "mono_mapping0['3.0_synset_offset'] = mono_mapping0[3]\n",
    "mono_mapping0 = mono_mapping0.drop([0,1,2,3],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly_mapping0 = pd.read_csv(SENSEMAP_FILE_POLY,header=None)\n",
    "\n",
    "poly_mapping0['score'] = [int(i.split(' ')[0]) for i in poly_mapping0[0]]\n",
    "poly_mapping0['2.1_sense_info'] = [i.split(' ')[1] for i in poly_mapping0[0]]\n",
    "poly_mapping0['3.0_sense_info_first'] = [i.split(' ')[2] if len(i.split(' ')) > 2 else '' for i in poly_mapping0[0]]\n",
    "poly_mapping0['3.0_sense_info_rest'] = [i.split(' ')[3:] if len(i.split(' ')) > 3 else '' for i in poly_mapping0[0]]\n",
    "\n",
    "poly_mapping0['2.1_sense_key'] = [i.split(';')[0] for i in poly_mapping0['2.1_sense_info']]\n",
    "poly_mapping0['2.1_synset_offset'] = [i.split(';')[1] for i in poly_mapping0['2.1_sense_info']]\n",
    "poly_mapping0['2.1_sense_number'] = [i.split(';')[2] for i in poly_mapping0['2.1_sense_info']]\n",
    "poly_mapping0['2.1_sense_key'] = [i[:-2] for i in poly_mapping0['2.1_sense_key']]\n",
    "\n",
    "poly_mapping0['3.0_first_sense_key'] = [i.split(';')[0] if len(i.split(';')) > 0 else '' for i in poly_mapping0['3.0_sense_info_first']]\n",
    "poly_mapping0['3.0_first_synset_offset'] = [i.split(';')[1] if len(i.split(';')) > 1 else '' for i in poly_mapping0['3.0_sense_info_first']]\n",
    "poly_mapping0['3.0_first_sense_number'] = [i.split(';')[2] if len(i.split(';')) > 2 else '' for i in poly_mapping0['3.0_sense_info_first']]\n",
    "poly_mapping0['3.0_first_sense_key'] = [i[:-2] for i in poly_mapping0['3.0_first_sense_key']]\n",
    "\n",
    "poly_mapping0 = poly_mapping0.drop([0,'2.1_sense_info','3.0_sense_info_first'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load WordNet 2.0 to 2.1 mappings\n",
    "mono_mapping1 = pd.read_csv(\"/local/software/wn-domains-3.2/sensemap-2.0-2.1/2.0to2.1.noun.mono\",header=None,sep=' ')\n",
    "\n",
    "mono_mapping1['2.0_sense_key'] = [i[:-2] for i in mono_mapping1[0]]\n",
    "mono_mapping1['2.0_synset_offset'] = mono_mapping1[1]\n",
    "mono_mapping1['2.1_sense_key'] = [i[:-2] for i in mono_mapping1[2]]\n",
    "mono_mapping1['2.1_synset_offset'] = mono_mapping1[3]\n",
    "mono_mapping1 = mono_mapping1.drop([0,1,2,3],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly_mapping1 = pd.read_csv(\"/local/software/wn-domains-3.2/sensemap-2.0-2.1/2.0to2.1.noun.poly\",header=None)\n",
    "\n",
    "poly_mapping1['score'] = [int(i.split(' ')[0]) for i in poly_mapping1[0]]\n",
    "poly_mapping1['2.0_sense_info'] = [i.split(' ')[1] for i in poly_mapping1[0]]\n",
    "poly_mapping1['2.1_sense_info_first'] = [i.split(' ')[2] if len(i.split(' ')) > 2 else '' for i in poly_mapping1[0]]\n",
    "poly_mapping1['2.1_sense_info_rest'] = [i.split(' ')[3:] if len(i.split(' ')) > 3 else '' for i in poly_mapping1[0]]\n",
    "\n",
    "poly_mapping1['2.0_sense_key'] = [i.split(';')[0] for i in poly_mapping1['2.0_sense_info']]\n",
    "poly_mapping1['2.0_synset_offset'] = [i.split(';')[1] for i in poly_mapping1['2.0_sense_info']]\n",
    "poly_mapping1['2.0_sense_number'] = [i.split(';')[2] for i in poly_mapping1['2.0_sense_info']]\n",
    "poly_mapping1['2.0_sense_key'] = [i[:-2] for i in poly_mapping1['2.0_sense_key']]\n",
    "\n",
    "poly_mapping1['2.1_first_sense_key'] = [i.split(';')[0] if len(i.split(';')) > 0 else '' for i in poly_mapping1['2.1_sense_info_first']]\n",
    "poly_mapping1['2.1_first_synset_offset'] = [i.split(';')[1] if len(i.split(';')) > 1 else '' for i in poly_mapping1['2.1_sense_info_first']]\n",
    "poly_mapping1['2.1_first_sense_number'] = [i.split(';')[2] if len(i.split(';')) > 2 else '' for i in poly_mapping1['2.1_sense_info_first']]\n",
    "poly_mapping1['2.1_first_sense_key'] = [i[:-2] for i in poly_mapping1['2.1_first_sense_key']]\n",
    "\n",
    "poly_mapping1 = poly_mapping1.drop([0,'2.0_sense_info','2.1_sense_info_first'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load WordNet Domains\n",
    "wnDomains = pd.read_csv(WORDNET_DOMAINS,header=None,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "domains = []\n",
    "\n",
    "for obj in objs:    \n",
    "    #Map from WordNet 3.0 to WordNet 2.1\n",
    "    offset_3 = obj.split(' ')[1][1:]\n",
    "    if len(mono_mapping0.loc[mono_mapping0['3.0_synset_offset']==int(offset_3)]) > 0: #found in mono_mapping\n",
    "        offset_21 = str(mono_mapping0.loc[mono_mapping0['3.0_synset_offset']==int(offset_3)].iloc[0]['2.1_synset_offset'])\n",
    "        while len(offset_21) < 8:\n",
    "            offset_21 = '0' + offset_21\n",
    "    elif len(poly_mapping0.loc[poly_mapping0['3.0_first_synset_offset']==offset_3]) > 0: #found in poly_mapping\n",
    "        offset_21 = poly_mapping0.loc[poly_mapping0['3.0_first_synset_offset']==offset_3].sort_values(by='score',ascending=False).iloc[0]['2.1_synset_offset']\n",
    "    else: #not found in either\n",
    "        domains.append('')\n",
    "        continue\n",
    "        \n",
    "    #print('offset_3',offset_3)\n",
    "    #print('offset_21',offset_21)\n",
    "        \n",
    "    #Map from WordNet 2.1 to WordNet 2.0\n",
    "    if len(mono_mapping1.loc[mono_mapping1['2.1_synset_offset']==int(offset_21)]) > 0: #found in mono_mapping\n",
    "        offset_2 = str(mono_mapping1.loc[mono_mapping1['2.1_synset_offset']==int(offset_21)].iloc[0]['2.0_synset_offset'])\n",
    "        while len(offset_2) < 8:\n",
    "            offset_2 = '0' + offset_2\n",
    "    elif len(poly_mapping1.loc[poly_mapping1['2.1_first_synset_offset']==offset_21]) > 0: #found in poly_mapping\n",
    "        offset_2 = poly_mapping1.loc[poly_mapping1['2.1_first_synset_offset']==offset_21].sort_values(by='score',ascending=False).iloc[0]['2.0_synset_offset']\n",
    "    else: #not found in either\n",
    "        domains.append('')\n",
    "        continue\n",
    "        \n",
    "    #print('offset_2',offset_2)\n",
    "        \n",
    "    #Figure out WordNet Domains\n",
    "    if len(wnDomains.loc[wnDomains[0]==offset_2+'-n']) > 0:\n",
    "        domains.append(wnDomains.loc[wnDomains[0]==offset_2+'-n'].iloc[0][1])\n",
    "    else:\n",
    "        domains.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_mapping = pd.DataFrame()\n",
    "final_mapping['object'] = objs\n",
    "final_mapping['domains'] = domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mapping.loc[final_mapping['domains']==\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domains = {}\n",
    "for it,row in final_mapping.iterrows():\n",
    "    d = row['domains'].split(' ')\n",
    "    for dom in d:\n",
    "        if dom in domains:\n",
    "            domains[dom].append(row['object'])\n",
    "        else:\n",
    "            domains[dom] = [row['object']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domainFeatures = pd.DataFrame(index=imageFeatures.index)\n",
    "domainFeatures['id'] = imageFeatures['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for domain,objects in domains.items():\n",
    "    total = imageFeatures[objects[0]]\n",
    "    for obj in objects[1:]:\n",
    "        total += imageFeatures[obj]\n",
    "    domainFeatures[domain] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now, combine all the smaller domains into the basic domains (to use for correlations)\n",
    "#This hierarchy comes from wn-domains-3.2/WDH-to-DDC-map.pdf\n",
    "#Not all domains are here because not all domains are represented in our 1,000 object categories\n",
    "basic_domains = {}\n",
    "basic_domains['history'] = ['history']\n",
    "basic_domains['art'] = ['art','painting','music','photography','theatre','cinema','jewellery']\n",
    "basic_domains['religion'] = ['religion']\n",
    "basic_domains['play'] = ['play']\n",
    "basic_domains['radio+tv'] = ['radio+tv']\n",
    "basic_domains['sport'] = ['sport','baseball','basketball','football','golf','rugby','soccer','table_tennis',\\\n",
    "                         'tennis','volleyball','skiing','hockey','swimming','racing','athletics','boxing',\\\n",
    "                         'fishing','hunting']\n",
    "basic_domains['agriculture'] = ['agriculture','animal_husbandry']\n",
    "basic_domains['food'] = ['food','gastronomy']\n",
    "basic_domains['home'] = ['home']\n",
    "basic_domains['architecture'] = ['architecture','town_planning','buildings','furniture']\n",
    "basic_domains['computer_science'] = ['computer_science']\n",
    "basic_domains['engineering'] = ['engineering','mechanics','astronautics','electrotechnology']\n",
    "basic_domains['telecommunication'] = ['telecommunication','telephony']\n",
    "basic_domains['medicine'] = ['medicine','pharmacy']\n",
    "basic_domains['astronomy'] = ['astronomy']\n",
    "basic_domains['biology'] = ['biology']\n",
    "basic_domains['animals'] = ['animals','entomology']\n",
    "basic_domains['plants'] = ['plants']\n",
    "basic_domains['chemistry'] = ['chemistry']\n",
    "basic_domains['earth'] = ['geology','metrology','geography']\n",
    "basic_domains['mathematics'] = ['mathematics']\n",
    "basic_domains['physics'] = ['physics','acoustics','atomic_physic','electronics','optics']\n",
    "basic_domains['anthropology'] = ['folklore']\n",
    "basic_domains['health'] = ['body_care']\n",
    "basic_domains['military'] = ['military']\n",
    "basic_domains['publishing'] = ['publishing']\n",
    "basic_domains['artisanship'] = ['artisanship']\n",
    "basic_domains['commerce'] = ['commerce']\n",
    "basic_domains['industry'] = ['industry']\n",
    "basic_domains['transport'] = ['transport','aviation','nautical','railway','vehicles']\n",
    "basic_domains['economy'] = ['economy','enterprise','banking','money']\n",
    "basic_domains['administration'] = ['administration']\n",
    "basic_domains['law'] = ['law']\n",
    "basic_domains['tourism'] = ['tourism']\n",
    "basic_domains['fashion'] = ['fashion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in domains.keys():\n",
    "    found = False\n",
    "    for domain in basic_domains:\n",
    "        if word in basic_domains[domain]:\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for domain,words in basic_domains.items():\n",
    "    temp = domainFeatures[words[0]]\n",
    "    for word in words[1:]:\n",
    "        temp += domainFeatures[word]\n",
    "    domainFeatures['basic_'+domain] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domainFeatures.to_csv(OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
