{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change to work with your setup\n",
    "RESULTS_FILE_NAME = \"data/prediction_results.csv\"\n",
    "GROUND_TRUTH_FILE = \"data/data_analytics_cleaned.csv\" #ground truth personality and gender in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RUN IF YOU DON'T HAVE RESULTS YET\n",
    "results = pd.DataFrame(columns=['label','classifier','trait','metric','result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LOAD EXISTING RESULTS\n",
    "results = pd.read_csv(RESULTS_FILE_NAME)\n",
    "results = results.drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(df, df_label, groundTruth, results, labels, linearRegression = True, svr = True, randomForest = True,\n",
    "           randomForest_pca = True, svr_pca = True, linearRegression_pca = True):\n",
    "    full_start = time.time()\n",
    "    cleaned_df = df[labels+['userid']]\n",
    "    dropped = ['userid','bfi_o','bfi_e','bfi_n','bfi_a','bfi_c']\n",
    "    merged = cleaned_df.merge(groundTruth[dropped])\n",
    "    \n",
    "    #filter out nan values\n",
    "    merged = merged.dropna(how='any')\n",
    "    \n",
    "    for clfIndex in range(6): #Try two regression techniques\n",
    "        if clfIndex == 0 and not linearRegression:\n",
    "            continue\n",
    "        elif clfIndex == 1 and not svr:\n",
    "            continue\n",
    "        elif clfIndex == 2 and not randomForest:\n",
    "            continue\n",
    "        elif clfIndex == 3 and not randomForest_pca:\n",
    "            continue\n",
    "        elif clfIndex == 4 and not svr_pca:\n",
    "            continue\n",
    "        elif clfIndex == 5 and not linearRegression_pca:\n",
    "            continue\n",
    "                \n",
    "        for trait in ['bfi_o','bfi_e','bfi_n','bfi_a','bfi_c']:\n",
    "            if clfIndex == 0:\n",
    "                print(\"Linear regression, no PCA\",trait)\n",
    "            elif clfIndex == 1:\n",
    "                print(\"SVR, no PCA\",trait)\n",
    "            elif clfIndex == 2:\n",
    "                print(\"Random Forest, no PCA\",trait)\n",
    "            elif clfIndex == 3:\n",
    "                print(\"Random Forest, PCA\",trait)\n",
    "            elif clfIndex == 4:\n",
    "                print(\"SVR, PCA\",trait)\n",
    "            elif clfIndex == 5:\n",
    "                print(\"Linear regression, PCA\",trait)\n",
    "                \n",
    "            start = time.time()\n",
    "            results = predict_one(merged,df_label,clfIndex,trait,results,labels)\n",
    "            print(\"One prediction took\",time.time()-start,\"seconds\")\n",
    "            \n",
    "    print(\"Full prediction routine took\",time.time()-full_start,\"seconds\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_one(df, df_label, clfIndex, trait, results,labels):\n",
    "    dropped = ['userid','bfi_o','bfi_e','bfi_n','bfi_a','bfi_c']\n",
    "    if clfIndex == 0 or clfIndex == 5:\n",
    "        clf = LinearRegression(n_jobs=-1)\n",
    "    else: #clfIndex == 2 or clfIndex == 3\n",
    "        clf = RandomForestRegressor(max_features=0.33, n_jobs=-1, random_state=42, n_estimators=100)\n",
    "    #SVR Classifier will be initialized later because the hyperparameters need to be fine-tuned\n",
    "    \n",
    "    average_r2 = 0\n",
    "    average_rmse = 0\n",
    "    average_absError = 0\n",
    "        \n",
    "    #Divide data into five folds\n",
    "    kf = cross_validation.KFold(len(df), n_folds=5, shuffle=True, random_state=42)\n",
    "    for train, test in kf: #cross validation to estimate accuracy\n",
    "        #Train data = other four folds\n",
    "        trainMat = df.iloc[train]\n",
    "        trainMat_text = df.iloc[train].drop(dropped,axis=1)\n",
    "        trainMat_target = df.iloc[train][trait]\n",
    "\n",
    "        #Test data = selected fold\n",
    "        testMat_text = df.iloc[test].drop(dropped,axis=1)\n",
    "        testMat_target = df.iloc[test][trait]\n",
    "        \n",
    "        #Fine-tune the hyperparameters of SVR\n",
    "        if clfIndex == 1 or clfIndex == 4:\n",
    "            C, epsilon, gamma = calculate_svr_params(trainMat,labels,trait)\n",
    "            clf = SVR(kernel='rbf', C=C, epsilon=epsilon, gamma=gamma)\n",
    "        \n",
    "        #PCA\n",
    "        if clfIndex == 5 or clfIndex == 4 or clfIndex == 3:\n",
    "            pca_components = calculate_num_pca(trainMat,clfIndex,labels,trait)\n",
    "            print(\"pca_components\",pca_components)\n",
    "            if pca_components > 0:\n",
    "                pca = PCA(n_components=pca_components)\n",
    "                trainMat_text = pca.fit_transform(trainMat_text)\n",
    "                testMat_text = pca.transform(testMat_text)\n",
    "\n",
    "        try:\n",
    "            #Train classifier on training data\n",
    "            clf.fit(trainMat_text,trainMat_target)\n",
    "            \n",
    "            #Run classifier on test data\n",
    "            predicted = clf.predict(testMat_text)\n",
    "        except:\n",
    "            print(\"Unexpected error while training classifier or predicting:\", sys.exc_info()[0])\n",
    "            return results\n",
    "        \n",
    "        #Evaluate how well classifier performed, save evaluation\n",
    "        average_r2 += r2_score(testMat_target,predicted)\n",
    "        average_rmse += math.sqrt(mean_squared_error(testMat_target,predicted))\n",
    "        \n",
    "        print('r2',r2_score(testMat_target,predicted))\n",
    "                \n",
    "        for i in range(len(testMat_target)):\n",
    "            average_absError += abs(list(testMat_target)[i]-predicted[i])\n",
    "                    \n",
    "    #Report average performance of the classifier (across five folds)\n",
    "    return write_results(results, df_label, clfIndex, trait, average_r2 / 5, average_rmse / 5, average_absError /5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_results(results, df_label, clfIndex, trait, r2, rmse, absError):\n",
    "    results = results.append({'label':df_label,'classifier':clfIndex,'trait':trait,'metric':'r2', 'result':r2}, \n",
    "                             ignore_index=True)\n",
    "    results = results.append({'label':df_label,'classifier':clfIndex,'trait':trait,'metric':'rmse', 'result':rmse},\n",
    "                             ignore_index=True)\n",
    "    results = results.append({'label':df_label,'classifier':clfIndex,'trait':trait,'metric':'absError', \n",
    "                              'result':absError},ignore_index=True)\n",
    "    results.to_csv(RESULTS_FILE_NAME)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_svr_params(trainMat,labels,trait):\n",
    "    #http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280664\n",
    "    dropped = ['userid','bfi_o','bfi_e','bfi_n','bfi_a','bfi_c']\n",
    "    X = trainMat.drop(dropped,axis=1)\n",
    "    y = trainMat[trait]\n",
    "    \n",
    "    kf = cross_validation.KFold(len(trainMat), n_folds=5, shuffle=True, random_state=42)\n",
    "    param_dists = {'C': uniform(loc=pow(2,-2),scale=pow(2,15)-pow(2,-2)),\n",
    "                   'gamma': uniform(loc=pow(2,-15),scale=pow(2,3)-pow(2,-15)),\n",
    "                   'epsilon': uniform(loc=0,scale=pow(2,2))}\n",
    "    search = RandomizedSearchCV(SVR(kernel='rbf'), param_distributions=param_dists, \n",
    "                                n_iter=40, cv=kf, random_state=42, verbose=False)\n",
    "\n",
    "    #start = time.time()\n",
    "    search.fit(X,y)\n",
    "    #print(\"Randomized grid search took\",time.time()-start,\"seconds\")\n",
    "    print(search.best_params_)\n",
    "    \n",
    "    return (search.best_params_['C'],search.best_params_['epsilon'],search.best_params_['gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_num_pca(trainMat,clfIndex,labels,trait):\n",
    "    dropped = ['userid','bfi_o','bfi_e','bfi_n','bfi_a','bfi_c']\n",
    "    if clfIndex == 0 or clfIndex == 5:\n",
    "        clf = LinearRegression(n_jobs=-1)\n",
    "    elif clfIndex == 1 or clfIndex == 4:\n",
    "        clf = SVR()\n",
    "    else: #clfIndex == 2 or clfIndex == 3\n",
    "        clf = RandomForestRegressor(max_features=0.33, n_jobs=-1, random_state=42, n_estimators=100)\n",
    "        \n",
    "    best_r2 = -1\n",
    "    best_pca = -1\n",
    "        \n",
    "    #For each potential PCA\n",
    "    for pca_components in range(0,len(labels),1000):\n",
    "        average_r2 = 0\n",
    "        \n",
    "        #Divide training data in 5 folds\n",
    "        kf = cross_validation.KFold(len(trainMat), n_folds=5, shuffle=True, random_state=42)\n",
    "        for sub_train, dev in kf:\n",
    "            #Sub training data = other four folds\n",
    "            subTrainMat_text = trainMat.iloc[sub_train].drop(dropped,axis=1)\n",
    "            subTrainMat_target = trainMat.iloc[sub_train][trait]\n",
    "            \n",
    "            #Dev data = selected fold\n",
    "            devMat_text = trainMat.iloc[dev].drop(dropped,axis=1)\n",
    "            devMat_target = trainMat.iloc[dev][trait]\n",
    "\n",
    "            if pca_components > 0:\n",
    "                pca = PCA(n_components=pca_components)\n",
    "                subTrainMat_text = pca.fit_transform(subTrainMat_text)\n",
    "                devMat_text = pca.transform(devMat_text)\n",
    "\n",
    "            try:\n",
    "                #Train classifier on training data\n",
    "                clf.fit(subTrainMat_text,subTrainMat_target)\n",
    "\n",
    "                #Run classifier on test data\n",
    "                predicted = clf.predict(devMat_text)\n",
    "            except:\n",
    "                print(\"Unexpected error while training classifier or predicting:\", sys.exc_info()[0])\n",
    "                return -1\n",
    "\n",
    "            #Evaluate how well classifier performed, save evaluation\n",
    "            average_r2 += r2_score(devMat_target,predicted)\n",
    "\n",
    "        #Technically r2_values doesn't have averages (you would need to divide the values by 5 to get averages)\n",
    "        #But since we're just comparing, it doesn't matter whether you divide them by 5 or not\n",
    "        if best_r2 < 0 or average_r2 > best_r2:\n",
    "            best_r2 = average_r2\n",
    "            best_pca = pca_components\n",
    "            \n",
    "    return best_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_num_features(trainMat,labels,trait):\n",
    "    clf = SVR()\n",
    "    \n",
    "    r2_values = {}\n",
    "        \n",
    "    #Divide training data in 5 folds\n",
    "    kf = cross_validation.KFold(len(trainMat), n_folds=5, shuffle=True, random_state=42)\n",
    "    for sub_train, dev in kf:\n",
    "        #Sub training data = other four folds\n",
    "        subTrainMat = trainMat.iloc[sub_train]\n",
    "        subTrainMat_target = trainMat.iloc[sub_train][trait]\n",
    "\n",
    "        #Dev data = selected fold\n",
    "        devMat = trainMat.iloc[dev]\n",
    "        devMat_target = trainMat.iloc[dev][trait]\n",
    "\n",
    "        #Using sub training data only, rank the features by importance\n",
    "        subTrainMat_chi = calculate_chi(subTrainMat,labels,trait)\n",
    "        subTrainMat_chi['feature'] = subTrainMat_chi.index\n",
    "        \n",
    "        chi_sorted = list(subTrainMat_chi.sort_values(trait,ascending=False)['feature'])\n",
    "        \n",
    "        #For each potential value of x\n",
    "        for x in range(0,len(labels),500):\n",
    "            #Choose the top x features\n",
    "            num_features = x\n",
    "            if x == 0:\n",
    "                num_features = len(labels)\n",
    "            keep = chi_sorted[:num_features]\n",
    "            subTrainMat_text = subTrainMat[[i for i in subTrainMat.columns.values if str(i) in keep]]\n",
    "            devMat_text = devMat[[i for i in devMat.columns.values if str(i) in keep]]\n",
    "\n",
    "            try:\n",
    "                #Train classifier on training data\n",
    "                clf.fit(subTrainMat_text,subTrainMat_target)\n",
    "\n",
    "                #Run classifier on test data\n",
    "                predicted = clf.predict(devMat_text)\n",
    "            except:\n",
    "                print(\"Unexpected error while training classifier or predicting:\", sys.exc_info()[0])\n",
    "                return -1\n",
    "\n",
    "            #Evaluate how well classifier performed, save evaluation\n",
    "            r2 = r2_score(devMat_target,predicted)\n",
    "\n",
    "            #Evaluate how well x performed across 5 folds\n",
    "            if num_features in r2_values:\n",
    "                r2_values[num_features] += r2\n",
    "            else:\n",
    "                r2_values[num_features] = r2\n",
    "\n",
    "    #Technically r2_values doesn't have averages (you would need to divide the values by 5 to get averages)\n",
    "    #But since we're just comparing, it doesn't matter whether you divide them by 5 or not\n",
    "                \n",
    "    #Choose best x\n",
    "    best_x = -1\n",
    "    best_r2 = -1\n",
    "    for x,average_r2 in r2_values.items():\n",
    "        if best_x == -1 or average_r2 > best_r2:\n",
    "            best_x = x\n",
    "            best_r2 = average_r2\n",
    "            \n",
    "    return best_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_baseline(df, groundTruth, results, labels):\n",
    "    full_start = time.time()\n",
    "    cleaned_df = df[labels+['userid']]\n",
    "    dropped = ['userid','bfi_o','bfi_e','bfi_n','bfi_a','bfi_c']\n",
    "    merged = cleaned_df.merge(groundTruth[dropped])\n",
    "    \n",
    "    #filter out nan values\n",
    "    merged = merged.dropna(how='any')\n",
    "                \n",
    "    for trait in ['bfi_o','bfi_e','bfi_n','bfi_a','bfi_c']:\n",
    "        print(trait)\n",
    "\n",
    "        start = time.time()\n",
    "        results = predict_one_baseline(merged,trait,results)\n",
    "        print(\"One prediction took\",time.time()-start,\"seconds\")\n",
    "\n",
    "    print(\"Full prediction routine took\",time.time()-full_start,\"seconds\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_one_baseline(df,trait,results):\n",
    "    average_r2 = 0\n",
    "    average_rmse = 0\n",
    "    average_absError = 0\n",
    "\n",
    "    kf = cross_validation.KFold(len(df), n_folds=5, shuffle=True, random_state=42)\n",
    "    for train, test in kf: #cross validation to estimate accuracy\n",
    "        trainMat_target = df.iloc[train][trait]\n",
    "        testMat_target = df.iloc[test][trait]\n",
    "\n",
    "        #Baseline: always predict the average value of the training matrix\n",
    "        averageValue = sum(trainMat_target)/len(trainMat_target)\n",
    "        predicted = [averageValue] * len(testMat_target)\n",
    "\n",
    "        average_r2 += r2_score(testMat_target,predicted)\n",
    "        average_rmse += math.sqrt(mean_squared_error(testMat_target,predicted))\n",
    "                \n",
    "        for i in range(len(testMat_target)):\n",
    "            average_absError += abs(list(testMat_target)[i]-predicted[i])\n",
    "            \n",
    "    return write_results(results, 'baseline', -1, trait, average_r2 / 5, average_rmse / 5, average_absError / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_features = ['unigrams','bigrams','trigrams','pos_unigrams','pos_bigrams','pos_trigrams','char_unigrams',\n",
    "                'char_bigrams','char_trigrams']\n",
    "dfs = []\n",
    "labels = []\n",
    "\n",
    "for feature in text_features:\n",
    "    df = pd.read_csv(\"data/text_features/\"+feature+\".csv\")\n",
    "    df = df.drop(\"Unnamed: 0\",axis=1)\n",
    "    dfs.append(df)\n",
    "    \n",
    "dfs[6]['userid'] = dfs[6]['id']\n",
    "dfs[6] = dfs[6].drop('id',axis=1)\n",
    "\n",
    "dfs[8]['userid'] = dfs[8]['id']\n",
    "dfs[8] = dfs[8].drop('id',axis=1)\n",
    "\n",
    "for df in dfs:\n",
    "    labels.append(list(df.columns.values[:-1]))\n",
    "    \n",
    "groundTruth = pd.read_csv(GROUND_TRUTH_FILE)\n",
    "groundTruth = groundTruth.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_features = ['basic','color','faceDetection','objects2','scene','sift','texture']\n",
    "\n",
    "image_dfs = []\n",
    "image_labels = []\n",
    "\n",
    "for feature in image_features:\n",
    "    df = pd.read_csv(IMAGE_FEATURE_FOLDER+'features_\"+feature+\".csv\")\n",
    "    if feature != 'basic':\n",
    "        df = df.drop(\"Unnamed: 0\",axis=1)\n",
    "    df['userid'] = df['id']\n",
    "    df = df.drop(\"id\",axis=1)\n",
    "    df = df.groupby('userid').mean()\n",
    "    df['userid'] = df.index\n",
    "    df = df.drop('imageNum',axis=1)\n",
    "    image_dfs.append(df)\n",
    "    \n",
    "    image_labels.append(list(df.columns.values[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict_baseline(dfs[0],groundTruth,results,labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_start = time.time()\n",
    "for index,feature in enumerate(text_features):\n",
    "    print('***',feature)\n",
    "    results = predict(dfs[index], feature, groundTruth, results, labels[index], svr=False, linearRegression=False)\n",
    "print(\"Entire loop took\",time.time()-loop_start,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_start = time.time()\n",
    "for index,feature in enumerate(image_features):\n",
    "    print('***',feature)\n",
    "    results = predict(image_dfs[index], feature, groundTruth, results, image_labels[index], \n",
    "                      svr=False, linearRegression=False)\n",
    "print(\"Entire loop took\",time.time()-loop_start,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images_all = image_dfs[0].merge(image_dfs[1])\n",
    "for df in image_dfs[2:]:\n",
    "    images_all = images_all.merge(df)\n",
    "\n",
    "images_all_labels = image_labels[0]\n",
    "for labels in image_labels[1:]:\n",
    "    images_all_labels += labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict(images_all, 'all', groundTruth, results, images_all_labels, \n",
    "                      svr=False, linearRegression=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_all = dfs[0].merge(dfs[1],on='userid')\n",
    "for df in dfs[2:]:\n",
    "    text_all = text_all.merge(df,on='userid')\n",
    "\n",
    "text_all_labels = [i for i in text_all.columns.values if i != 'userid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict(text_all, 'text_all', groundTruth, results, text_all_labels, \n",
    "                      svr=False, linearRegression=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features = text_all.merge(images_all,on='userid')\n",
    "all_labels = [i for i in all_features.columns.values if i != 'userid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict(all_features, 'text_image_all', groundTruth, results, all_labels, \n",
    "                      svr=False, linearRegression=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_start = time.time()\n",
    "for index,feature in enumerate(text_features):\n",
    "    print('***',feature)\n",
    "    results = predict(dfs[index], feature, groundTruth, results, labels[index], svr=False, randomForest=False)\n",
    "print(\"Entire loop took\",time.time()-loop_start,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_start = time.time()\n",
    "for index,feature in enumerate(image_features):\n",
    "    print('***',feature)\n",
    "    results = predict(image_dfs[index], feature, groundTruth, results, image_labels[index], \n",
    "                      svr=False, randomForest=False)\n",
    "print(\"Entire loop took\",time.time()-loop_start,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict(images_all, 'all', groundTruth, results, images_all_labels, \n",
    "                      svr=False, randomForest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict(text_all, 'text_all', groundTruth, results, text_all_labels, \n",
    "                      svr=False, randomForest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict(all_features, 'text_image_all', groundTruth, results, all_labels, \n",
    "                      svr=False, randomForest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_start = time.time()\n",
    "for index,feature in enumerate(text_features):\n",
    "    print('***',feature)\n",
    "    results = predict(dfs[index], feature, groundTruth, results, labels[index], svr=False, randomForest=False,\n",
    "                     linearRegression=False,svr_pca=False)\n",
    "print(\"Entire loop took\",time.time()-loop_start,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_start = time.time()\n",
    "for index,feature in enumerate(image_features):\n",
    "    print('***',feature)\n",
    "    results = predict(image_dfs[index], feature, groundTruth, results, image_labels[index], \n",
    "                      svr=False, randomForest=False, linearRegression=False, svr_pca=False)\n",
    "print(\"Entire loop took\",time.time()-loop_start,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict(images_all, 'all', groundTruth, results, images_all_labels, \n",
    "                      svr=False, randomForest=False, linearRegression=False,svr_pca=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict(text_all, 'text_all', groundTruth, results, text_all_labels, \n",
    "                      svr=False, randomForest=False,linearRegression=False,svr_pca=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict(all_features, 'text_image_all', groundTruth, results, all_labels, \n",
    "                      svr=False, randomForest=False, linearRegression=False,svr_pca=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loop_start = time.time()\n",
    "for index,feature in enumerate(image_features):\n",
    "    print('***',feature)\n",
    "    results = predict(image_dfs[index], feature, groundTruth, results, image_labels[index], \n",
    "                      randomForest=False, randomForest_pca=False, linearRegression=False, svr_pca=False,\n",
    "                      linearRegression_pca=False)\n",
    "print(\"Entire loop took\",time.time()-loop_start,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_start = time.time()\n",
    "for index,feature in enumerate(text_features):\n",
    "    print('***',feature)\n",
    "    results = predict(dfs[index], feature, groundTruth, results, labels[index],\n",
    "                      randomForest=False, randomForest_pca=False, linearRegression=False, svr_pca=False,\n",
    "                      linearRegression_pca=False)\n",
    "print(\"Entire loop took\",time.time()-loop_start,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
